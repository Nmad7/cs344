Exercise 2.1
1. Which of the local search algorithms solves the problem? How well does each algorithm do?
Both of the local search algorithms solves the problem correctly. Each algorithm finds the exact maximum of the graph.
2. Which algorithm works more quickly?
Hill climbing solves the problem more quickly than annealing solution.
3. Does the starting value for x make any difference? Why or why not?
The starting should not
4. What affect does changing the delta step value make on each algorithm? Why?
As the delta tells each algorithm how far to jump each time on the graph, making
the delta very small means the algorithms have to make a large amount of small jumps
to make it to the maximum of the graph extending the time it takes to get to the max.
The algorithms will not also not find the max if, by only jumping by that, the max is unattainable.
5. What is the purpose of the exp_schedule() method in the simulated annealing function call?
The exp_scheduling is the method that cools down the temperature over time so simulated annealing makes
less extreme jumps over time.

Exercise 2.2
1. How do each of the algorithms do on this problem space? Why?
Both algorithms do not always find the maximum value. For hillclimbing, it will always just go up the nearest
incline in the graph until it reaches the local maximum. The simulated annealing algorithm usually gets closer
due to its random jumps but still will not always find the maximum.
2. Does the starting value make any difference here?
The starting value makes a big difference as starting at a small x or an x on a declining slope will lead
hillclimbing to find a smaller local maximum and means that simulated annealing has to make many more jumps
which it will do less of as time goes on.
3. Does modifying the step size (i.e., delta) affect the operation of the two algorithms? Why or why not?
Yes, modifying the step size to be larger means the algorithms will jump further for every move they make.
This means they will make more extreme movements around the graph sometimes for better and sometimes for worse.
4. What are the maximum and minimum possible values here, and how do the two algorithms score with respect to them?
Respecting a maximum x of 30 means the maximum value should be 30 at (30,30). The two algorithms are generally poor
at finding this number but simulated annealing almost always gets closer than hill climbing.

Exercise 2.3
1. How does each algorithm do with these restarts? Why?
Both hillclimb and simulated annealing do well the restarts and generally find the best value (given
a reasonable amount of restarts) if the best value of the restarts is kept.
2 What are the average values of the runs for each of the algorithms?
Assuming a delta of 1, the average value of the runs for hillclimbing was around 15.
While the simulated annealing often keeps going past our max value for our graph, the
average of its runs is generally around 20 which is better than hillclimbing.

3. If one of the algorithms does better, explain why; if not, explain why not.
Both algorithms generally find the maximum of the graph when restarted enough times and
therefore do about the same (with simulated annealing taking longer). While on
average hillclimbing preforms worse in the individual case, it is able to find the max
if it is restarted enough.
Exercise 2.4
1. For which algorithm does beam search make the most sense?
It makes the most sense to use beam search with hill climbing.
2. How many solutions could you maintain with reasonable space and time constraints?
You can maintain a very large amount of solutions depending on the hardware as each
solution set is only k large for each level (local beam trims off bad ones). This means
local beam is only storing current states at any time. Local beam search would also
filter out many bad initial states very quickly making it fairly fast.
3. How would you modify the code to implement beam search? How is it different from random restarts, if at all?
In comparison to random restarts, in local beam search one does not fully
follow through with every initial state all the way. Instead, after initial states
are chosen they are pruned down to only the top "k" states who have the best value.
To do this, I would start with initial states and then check all the next possible state values.
These values would then be put into a list so a limited number of states with the top value
could be chosen to continue from. Then this would repeat until the goal is reached.
