{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1  Create the spam filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Probability table of words after loading in corpus: {'do': 0.3333333333333333, 'i': 0.01, 'like': 0.3333333333333333, 'green': 0.01, 'eggs': 0.01, 'and': 0.01, 'ham': 0.01, 'I': 0.99, 'am': 0.99, 'spam': 0.99, 'not': 0.99, 'that': 0.99, 'spamiam': 0.99}\n",
      "Probability of being spam: 0.05529157667386612\n",
      "False\n",
      "Probability of being spam: 0.9999999999946227\n",
      "True\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy\n",
    "\n",
    "def unique_counter(unique_list, corpus):\n",
    "    '''\n",
    "    add unique words from a corpus to a list\n",
    "    '''\n",
    "    for sample in corpus:\n",
    "        for word in sample:\n",
    "            # check if word in this sample has already been added\n",
    "            if word not in unique_list:\n",
    "                unique_list.append(word)\n",
    "    return unique_list\n",
    "\n",
    "def word_hash(corpus):\n",
    "    '''\n",
    "    create a hash for each word in a corpus of the number of times it appears\n",
    "    '''\n",
    "    count_hash = {}\n",
    "    for sample in corpus:\n",
    "        done = []\n",
    "        for word in sample:\n",
    "            # check if word in this sample has already been counted\n",
    "            if word not in done:\n",
    "                # check if word already has an entry and if so\n",
    "                # update the new count\n",
    "                if word in count_hash:\n",
    "                    count_hash[word] = sample.count(word) + count_hash[word]\n",
    "                else:\n",
    "                    count_hash[word] = sample.count(word)\n",
    "                done.append(word)\n",
    "    return count_hash\n",
    "\n",
    "def word_prob(good, bad, word, ngood, nbad):\n",
    "    '''\n",
    "    compute the probability that a word is spam\n",
    "    '''\n",
    "    g = 2 * good.get(word, 0)\n",
    "    b = bad.get(word, 0)\n",
    "    if g + b >= 1:\n",
    "        return max(0.01, min(0.99, min(1.0, b / nbad) / (min(1.0, g / ngood) + min(1.0, b / nbad))))\n",
    "    return -1\n",
    "\n",
    "\n",
    "def prob_hash(good, bad, ngood, nbad, word_list):\n",
    "    '''\n",
    "    find the probability a word means something is spam and put this value in a hash\n",
    "    '''\n",
    "    spam_prob = {}\n",
    "    for word in word_list:\n",
    "        spam_prob[word] = word_prob(good, bad, word, ngood, nbad)\n",
    "    return spam_prob\n",
    "\n",
    "\n",
    "def is_mail_spam_probability(mail_corpus, prob_hash):\n",
    "    '''\n",
    "    a way to check if new mail is spam\n",
    "    assumes the mail comes in the form of a list of tokens\n",
    "    '''\n",
    "    # Get all the probabilities in the mail corpus\n",
    "    # (Ignoring the self imposed 15 word limit due to average short length)\n",
    "    # if word not in the probs hash then assign it .4\n",
    "    probs = []\n",
    "    for word in mail_corpus:\n",
    "        if word in prob_hash:\n",
    "            probs.append(prob_hash[word])\n",
    "        else:\n",
    "            probs.append(0.4)\n",
    "    # Get combined probability\n",
    "    compliment = []\n",
    "    for i in range(len(probs)):\n",
    "        compliment.append(1 - probs[i])\n",
    "    combined = numpy.prod(probs) / (numpy.prod(probs) + numpy.prod(compliment))\n",
    "    if combined > 0.9:\n",
    "        print(\"Probability of being spam:\", str(combined))\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Probability of being spam:\", str(combined))\n",
    "        return False\n",
    "\n",
    "# a corpus has to a be a list of lists which contain strings\n",
    "spam_corpus = [[\"I\", \"am\", \"spam\", \"spam\", \"I\", \"am\"], [\"I\", \"do\", \"not\", \"like\", \"that\", \"spamiam\"]]\n",
    "ham_corpus = [[\"do\", \"i\", \"like\", \"green\", \"eggs\", \"and\", \"ham\"], [\"i\", \"do\"]]\n",
    "\n",
    "# get unique words in a each corpus\n",
    "word_list = []\n",
    "word_list = unique_counter(word_list, ham_corpus)\n",
    "word_list = unique_counter(word_list, spam_corpus)\n",
    "\n",
    "# get count hashtable for each corpus\n",
    "spam_hash = word_hash(spam_corpus)\n",
    "ham_hash = word_hash(ham_corpus)\n",
    "# get size of each\n",
    "ngood = len(ham_corpus)\n",
    "nbad = len(spam_corpus)\n",
    "\n",
    "# generate a  probability table an email with that word is spam\n",
    "spam_prob_hash = prob_hash(ham_hash, spam_hash, ngood, nbad, word_list)\n",
    "print(\"Probability table of words after loading in corpus:\", str(spam_prob_hash))\n",
    "\n",
    "# test with new messages\n",
    "test = [\"This\", \"is\", \"a\", \"clean\", \"message\", \"for\", \"enjoyment\"]\n",
    "test2 = [\"I\", \"am\", \"very\", \"much\", \"spam\", \"spam\",  \"I\", \"very\", \"much\", \"am\"]\n",
    "print(is_mail_spam_probability(test, spam_prob_hash))\n",
    "print(is_mail_spam_probability(test2, spam_prob_hash))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2 Why is this implimentation Bayesian?\n",
    "This implementation of the spam filter is Bayesian because it uses past calculated information \n",
    "and probabilities to calculate the probability a new message is spam.\n",
    "This algorithm does not just consider the words with a high spam probability (like many spam feature\n",
    "recognizing systems) but also the ones that have a low spam probability. Using the overall probability \n",
    "is more Bayesian. It is also Bayesian in giving a new probability (that the email is spam)\n",
    "by combining other probabilities (the word within it indicate it is spam).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.a Implement Figure 14.12a Bayesian Network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "False: 0.5, True: 0.5\n",
      "False: 0.9, True: 0.1\n",
      "False: 0.952, True: 0.0476\n",
      "False: 0.01, True: 0.99\n",
      "False: 0.639, True: 0.361\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from probability import BayesNet, enumeration_ask\n",
    "\n",
    "# Utility variables\n",
    "T, F = True, False\n",
    "\n",
    "wet = BayesNet([\n",
    "    ('Cloudy', '', 0.5),\n",
    "    ('Sprinkler', 'Cloudy', {T: 0.1, F: 0.50}),\n",
    "    ('Rain', 'Cloudy', {T: 0.80, F: 0.2}),\n",
    "    ('WetGrass', 'Sprinkler Rain', {(T, T): 0.99, (T, F): 0.90, (F, T): 0.90, (F, F): 0.00})\n",
    "    ])\n",
    "\n",
    "# Compute P(cloudy)\n",
    "print(enumeration_ask('Cloudy', dict(), wet).show_approx())\n",
    "\n",
    "# Compute P(Sprinkler | cloudy)\n",
    "print(enumeration_ask('Sprinkler', dict(Cloudy=T), wet).show_approx())\n",
    "\n",
    "# Compute P(Cloudy| the sprinkler is running and it’s not raining)\n",
    "print(enumeration_ask('Cloudy', dict(Sprinkler=T, Rain=F), wet).show_approx())\n",
    "\n",
    "# Compute P(WetGrass | it’s cloudy, the sprinkler is running and it’s raining)\n",
    "print(enumeration_ask('WetGrass', dict(Cloudy=T, Sprinkler=T, Rain=T), wet).show_approx())\n",
    "\n",
    "# Compute P(Cloudy | the grass is not wet)\n",
    "print(enumeration_ask('Cloudy', dict(WetGrass=F), wet).show_approx())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.b Compute the number of independent values in the full joint probability\n",
    " There are 4 binary variables in this system meaning that the number of values\n",
    " should be 2^4 = 16\n",
    "\n",
    "## 2.c Compute the number of independent values in the Bayesian network \n",
    "Based on the Bayesian network figure, it will have 9 values.\n",
    "\n",
    "## 2.d Compute probabilities by hand\n",
    "- P(Cloudy) = <T=.5,F=.5> (given in text)\n",
    "\n",
    "- P(Sprinker | cloudy) <0.1,0.9> (given in text)\n",
    "\n",
    "- P(Cloudy| sprinkler, ¬rain) = α P(cloudy, sprinkler, ¬rain) = <br>\n",
    "  α <P(S|C)* P(¬R|C)* (P(C), P(S|¬C)* P(¬R|¬C)* P(¬C)> =\n",
    "  α<.1* .2* .5 , .5* .8* .5> = α<.01 , .2> = <.048 , .952>\n",
    "\n",
    "\n",
    "- P(WetGrass | cloudy, sprinkler, rain) = α P(wetgrass, cloudy, sprinkler, rain)\n",
    "  α <P(W | S,R) * P(S|C) * P(R|C) * P(C) , P(¬W | S,R) * P(S|C) * P(R|C) * P(C)> = \n",
    "  α < .99* .10* .80* .5 , .01* .10* .80* .5> = α <.0396 , .0004 > = <.99 , .01>\n",
    "\n",
    "- P(Cloudy | ¬wetgrass) = α P(Cloudy,¬wetgrass, rain, sprinkler)<br>\n",
    "  α <P(C) * P(R|C) * P(S|C)* P(¬W | S,R) + P(C) * P(¬R|C) * P(S|C) * P(¬W | S,¬R) <br>\n",
    "  +P(C) * P(R|C) * P(¬S|C) * P(¬W | ¬S,R)  + P(C) * P(¬R|C) * P(¬S|C) * P(¬W | ¬S,¬R) , <br>\n",
    "  P(¬C) * P(R|¬C) * P(S|¬C) * P(¬W | S,R) + P(¬C) * P(¬R|¬C) * P(S|¬C) * P(¬W | S,¬R) <br>\n",
    "  +P(¬C) * P(R|¬C) * P(¬S|¬C) * P(¬W | ¬S,R) +P(¬C) * P(¬R|¬C) * P(¬S|¬C) * P(¬W | ¬S,¬R)><br>\n",
    "  α <.5* .8* .1* .01 + .5* .2* .1* .1 + .5* .8* .9* .1 + .5* .2* .9* 1 ,\n",
    "  .5 *.2 *.5 *.01 + .5 *.8 *.5 *.1 + .5 *.2 *.5 *.1 + .5 *.8 *.5 *1><br>\n",
    "  α <.1272,.2255> = <.361,.639>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}