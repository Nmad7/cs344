{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Information Gain of Price\n",
    "Gain(Price)= Entropy(restaurant) - Remainder(price?)\n",
    "\n",
    "Remainder(price?)= 7/12×entropy(cheap) + 2/12×entropy(medium) + 3/12×entropy(expensive)  \n",
    "\n",
    "Remainder(price?)= 7/12(-1(3/7×log2(3/7)+4/7×log2(4/7))) + 2/12(-1(2/2×log2(2/2) + 0)) + 3/12(-1(1/3×log2(1/3) + 2/3×log2(2/3)))\n",
    "\n",
    "Remainder(price?)= .8042903712"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. XOR neural network\n",
    "It is possible to build a XOR function with a neural network as long as multiple layers are used.\n",
    "An XOR function can be created by combining other base functions: the OR function, the NAND function, and the AND function.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Boston Housing Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# code to print dimensions\n",
    "def printDataStructureInfo(Input_Dataset):\n",
    "    print(\n",
    "        'count: {} \\\n",
    "        \\ndimensions: {} \\\n",
    "        \\nshape: {} \\\n",
    "        \\n'.format(\n",
    "            len(Input_Dataset),\n",
    "            Input_Dataset.ndim,\n",
    "            Input_Dataset.shape\n",
    "        ),\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gain(Price) = 1 - .8042903712 = .1957096288‬\n",
    "\n",
    "We gain more information from Patrons than from Price, but\n",
    "Price gains more information than Type which gives none.\n",
    "\n",
    "There are many ways of loading in data and splitting it for Keras. I chose to use numpy split."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Boston Housing\n",
      "count: 506         \n",
      "dimensions: 2         \n",
      "shape: (506, 14)         \n",
      "\n",
      "trainging_target\n",
      "count: 328         \n",
      "dimensions: 1         \n",
      "shape: (328,)         \n",
      "\n",
      "training_data\n",
      "count: 328         \n",
      "dimensions: 2         \n",
      "shape: (328, 13)         \n",
      "\n",
      "validate\n",
      "count: 76         \n",
      "dimensions: 2         \n",
      "shape: (76, 13)         \n",
      "\n",
      "testing\n",
      "count: 102         \n",
      "dimensions: 2         \n",
      "shape: (102, 13)         \n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import boston_housing\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv\")\n",
    "\n",
    "print(\"Boston Housing\")\n",
    "printDataStructureInfo(df)\n",
    "\n",
    "# uses numpy split and sample to randomize the data (source: https://datascience.stackexchange.com/questions/15135/train-test-validation-set-splitting-in-sklearn)\n",
    "# leaves the first 65% for the training, from 65% to 80% for the validation, and from 80% to the end for the test data\n",
    "training, validate, testing = np.split(df.sample(frac=1), [int(.65*len(df)), int(.80*len(df))])\n",
    "\n",
    "# split target data\n",
    "training_data = training.values[:,0:len(df.columns)-1]\n",
    "validate_data = validate.values[:,0:len(df.columns)-1]\n",
    "testing_data = testing.values[:,0:len(df.columns)-1]\n",
    "training_targets = training.values[:,len(df.columns)-1]\n",
    "validate_targets = validate.values[:,len(df.columns)-1]\n",
    "testing_targets = testing.values[:,len(df.columns)-1]\n",
    "\n",
    "# Final part of question a in demonstrating printing works\n",
    "print(\"trainging_target\")\n",
    "printDataStructureInfo(training_targets)\n",
    "print(\"training_data\")\n",
    "printDataStructureInfo(training_data)\n",
    "print(\"validate\")\n",
    "printDataStructureInfo(validate_data)\n",
    "print(\"testing\")\n",
    "printDataStructureInfo(testing_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One synthetic feature one could make from this data set is combining property age with \n",
    "lower status as it would make sense that generally the more older houses in a suburb\n",
    "the poorer those in the suburb would be. To do this, I would combine through dividing these two before \n",
    "splitting into training and testing parts. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
      "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
      "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
      "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
      "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
      "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
      "\n",
      "        b  lstat  medv  percent_lower_class_per_percent_old_house  \n",
      "0  396.90   4.98  24.0                                   0.076380  \n",
      "1  396.90   9.14  21.6                                   0.115843  \n",
      "2  392.83   4.03  34.7                                   0.065957  \n",
      "3  394.63   2.94  33.4                                   0.064192  \n",
      "4  396.90   5.33  36.2                                   0.098339  \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "df[\"percent_lower_class_per_percent_old_house\"] = (df[\"lstat\"] / df[\"age\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}